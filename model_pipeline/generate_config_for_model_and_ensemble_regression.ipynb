{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:40.172735Z",
     "start_time": "2019-08-29T22:52:40.152143Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:42.150281Z",
     "start_time": "2019-08-29T22:52:40.324037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../config/initialize_nospark.ipynb\n",
    "\n",
    "from copy import deepcopy\n",
    "from datetime import date\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:44.107585Z",
     "start_time": "2019-08-29T22:52:42.152368Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('model_pipeline')\n",
    "from Ensemble import Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set root dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:44.182655Z",
     "start_time": "2019-08-29T22:52:44.109286Z"
    }
   },
   "outputs": [],
   "source": [
    "user = !whoami\n",
    "user = user[0]\n",
    "ROOT=f'/Users/{user}/Dropbox/data_science/'\\\n",
    "    'modeling-football-outcomes'\n",
    "os.chdir(ROOT)\n",
    "\n",
    "MODELS_DIR=f'{ROOT}/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:44.249285Z",
     "start_time": "2019-08-29T22:52:44.185516Z"
    }
   },
   "outputs": [],
   "source": [
    "MODELS_DIR=f'{ROOT}/models'\n",
    "MODEL_ID = str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:44.310335Z",
     "start_time": "2019-08-29T22:52:44.252351Z"
    }
   },
   "outputs": [],
   "source": [
    "# JSON_CONFIG_GROUP = 'ensemble_baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary version of model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:44.370634Z",
     "start_time": "2019-08-29T22:52:44.314031Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model_id': MODEL_ID,\n",
    "    'models_dir': MODELS_DIR\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source data for model\n",
    "* features\n",
    "* labels\n",
    "* Note: can modify/create tables here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:44.915324Z",
     "start_time": "2019-08-29T22:52:44.862911Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['features_tbl'] = 'features.combined_0601'\n",
    "model_dict['labels_tbl'] = 'labels.combined_0601'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:46.225139Z",
     "start_time": "2019-08-29T22:52:46.071435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = list(pd.read_csv('data/features/combined_0601.csv').columns[3:])\n",
    "len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns from tables\n",
    "* index: unique identifier in features/labels table (must be in both)\n",
    "* label column, and indicator of what is a positive label\n",
    "  * currently not supported: multi-class\n",
    "  * code will binarize\n",
    "* list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:50.662422Z",
     "start_time": "2019-08-29T22:52:50.606748Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['index'] = ['game_id']\n",
    "model_dict['label_col'] = 'final_margin'\n",
    "model_dict['pos_labels'] = [1]\n",
    "model_dict['neg_labels'] = [-1]\n",
    "model_dict['features_list'] = all_features\n",
    "\n",
    "model_dict['features_list'].sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Sets\n",
    "* random seeds for reproducibility\n",
    "* number of folds for cross-validation (value of <= 1 doesn't do k-fold\n",
    "* global_dataset_proportions\n",
    " * proportion of the data for each of training, scoring only, holdout, and throwaway\n",
    " * generated using stratified sampling\n",
    "* dimensional_dataset_proportions\n",
    " * post-processing after global_dataset_proportions\n",
    " * idea is to move specific field values, e.g. move certain seasons to the holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: use cross-validation data from another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:54.895273Z",
     "start_time": "2019-08-29T22:52:54.841452Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['model_cv_to_use'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV parameters, when not using another model CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample usage for Dimensional Dataset Proportions\n",
    "```python\n",
    "model_dict['dimensional_dataset_proportions'] = {\n",
    "        'throw_away': [\n",
    "            {\n",
    "                'vals': [\n",
    "                    0\n",
    "                ], \n",
    "                'dim': 'is_home',\n",
    "                'prop_to_move': 1.0, \n",
    "                'from_groups': [\n",
    "                    'training',\n",
    "                    'holdout',\n",
    "                    'scoring_only'\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:56.600277Z",
     "start_time": "2019-08-29T22:52:56.543772Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['fold_seed'] = 99\n",
    "model_dict['dataset_seed'] = 9\n",
    "model_dict['kfolds'] = 5\n",
    "model_dict['strata_cols'] = ['season','week_id']\n",
    "\n",
    "model_dict['global_dataset_proportions'] = {\n",
    "        'training': 1.,\n",
    "        'holdout': 0,\n",
    "        'throw_away': 0,\n",
    "        'scoring_only': 0\n",
    "    }\n",
    "\n",
    "# DEFAULT: model_dict['dimensional_dataset_proportions'] = {}\n",
    "model_dict['dimensional_dataset_proportions'] = {\n",
    "        'holdout': [\n",
    "            {\n",
    "                'vals': [\n",
    "                    17, \n",
    "                    18, \n",
    "                    19, \n",
    "                    20, \n",
    "                    21, \n",
    "                    22\n",
    "                ], \n",
    "                'dim': 'week_id', \n",
    "                'prop_to_move': 1.0, \n",
    "                'from_groups': [\n",
    "                    'training', \n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        'holdout': [{\n",
    "            'vals': [2016,2017],\n",
    "            'dim': 'season',\n",
    "            'prop_to_move': 1.0,\n",
    "            'from_groups': ['training', 'scoring_only']}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choice\n",
    "* package/class name as a string\n",
    "* parameters as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:10.667569Z",
     "start_time": "2019-08-28T00:23:10.623772Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_dict['model'] = 'sklearn.ensemble.GradientBoostingClassifier'\n",
    "# model_dict['model_params'] = {\n",
    "#     'learning_rate': 0.1, \n",
    "#     'n_estimators': 200, \n",
    "#     'max_features': 'auto', \n",
    "#     'subsample': 0.9, \n",
    "#     'random_state': 9, \n",
    "#     'max_depth': 12, \n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:52:59.261715Z",
     "start_time": "2019-08-29T22:52:59.187650Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['model'] = 'xgboost.XGBRegressor'\n",
    "model_dict['model_params'] = {\n",
    "        'n_jobs': 1,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 100, \n",
    "        'max_features': 'auto', \n",
    "        'booster': 'gbtree', \n",
    "        'silent': True, \n",
    "        'nthread': None, \n",
    "        'subsample': 0.5, \n",
    "        'random_state': 9, \n",
    "        'objective': 'reg:linear',\n",
    "        'max_depth': 6, \n",
    "        'gamma': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actions to perform and data to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:00.999802Z",
     "start_time": "2019-08-29T22:53:00.944223Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['save'] = {\n",
    "    'cv_data': True,\n",
    "    'serialized_models': False,\n",
    "    'cv_scores': True,\n",
    "    'holdout_scores': False\n",
    "}\n",
    "\n",
    "model_dict['actions'] = {\n",
    "        'do_train_and_score_cv': True,\n",
    "        'do_score_holdout': False,\n",
    "        'do_evaluate': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out model.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:03.956988Z",
     "start_time": "2019-08-29T22:53:03.898216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/model__regression_example.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_json_path = 'model_configs/model__regression_example.json'\n",
    "model_json_path\n",
    "\n",
    "with open(model_json_path,'w') as w:\n",
    "    json.dump(model_dict, w, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dictionary version of evaluate.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:04.950697Z",
     "start_time": "2019-08-29T22:53:04.901220Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict = {\n",
    "    'model_id': MODEL_ID,\n",
    "    'models_dir': MODELS_DIR\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Labels\n",
    "* labels --> names (note: keys should be strings)\n",
    "* name for success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:05.831695Z",
     "start_time": "2019-08-29T22:53:05.783600Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict['label_map'] = {\n",
    "    '1': 'Won',\n",
    "    '0': 'Lost'\n",
    "}\n",
    "evaluate_dict['success_name'] = 'Win Rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins to plot\n",
    "* plot_bins: \n",
    "   * Number of bins to plot (i.e. number of bars on the bar chart)\n",
    "* bin_types:\n",
    "   * \"Bin\" puts scores into uniform bins, e.g. [0, 0.10], (0.10, 0.20], ..., (0.9, 1.0]\n",
    "   * \"Percentile\" bins scores into ntiles determined by plot_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:06.240718Z",
     "start_time": "2019-08-29T22:53:06.177896Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict['bin_types'] = ['Bin', 'Percentile']\n",
    "evaluate_dict['plot_bins'] = [10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold Metrics to Plot\n",
    "* metrics evaluated at each of 100 score threshold points\n",
    "* currently only supports Accuracy and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:06.638669Z",
     "start_time": "2019-08-29T22:53:06.580215Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict['threshold_metrics'] = ['Accuracy','F1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy at Top 'N' plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:07.305866Z",
     "start_time": "2019-08-29T22:53:07.249985Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict['accuracy_at_topn'] = {\n",
    "        'week_id__season': [1, 16],\n",
    "        'season': [1, 200, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:07.712518Z",
     "start_time": "2019-08-29T22:53:07.655220Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict['regression_evaluation'] = {\n",
    "    'comparison':  0, \n",
    "    'label': 'did_win', \n",
    "    'round_score': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:07.947678Z",
     "start_time": "2019-08-29T22:53:07.895940Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_dict['to_plot'] = {\n",
    "    'ridge': True,\n",
    "    'thresholds': True,\n",
    "    'bins': True,\n",
    "    'roc': True,\n",
    "    'accuracy_by_top_n': True,\n",
    "    'regression__distributions': True,\n",
    "    'regression__scatter': True,\n",
    "    'regression__residuals_by_season_week': True,\n",
    "    'regression__confusion_matrix': True,\n",
    "    'shap__feature_importance': True,\n",
    "    'shap__dependence_plots': False,\n",
    "    'feature_importance': True\n",
    "}\n",
    "\n",
    "evaluate_dict['save'] = {\n",
    "    'plots': False,\n",
    "    'data': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out evaluate.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:08.918331Z",
     "start_time": "2019-08-29T22:53:08.854101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/evaluate__regression_example.json'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_json_path = 'model_configs/evaluate__regression_example.json'\n",
    "eval_json_path\n",
    "\n",
    "with open(eval_json_path,'w') as w:\n",
    "    json.dump(evaluate_dict, w, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:26.844891Z",
     "start_time": "2019-08-28T00:23:11.259358Z"
    }
   },
   "outputs": [],
   "source": [
    "from ExecuteModelPipeline import ExecuteModelPipeline\n",
    "model_pipeline = ExecuteModelPipeline(model_json_path, eval_json_path, 'Y')\n",
    "model_pipeline.execute_model_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:27.279017Z",
     "start_time": "2019-08-28T00:23:26.846917Z"
    }
   },
   "outputs": [],
   "source": [
    "!open {MODELS_DIR}/{MODEL_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an ensemble, using the above model as a template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the sub-model template: modify model.json (model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bootstrap: select 50% of the data for each model, with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:16.467501Z",
     "start_time": "2019-08-29T22:53:16.420610Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['global_dataset_proportions']['training'] = 0.5\n",
    "model_dict['global_dataset_proportions']['throw_away'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save options for ensemble's sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:16.990589Z",
     "start_time": "2019-08-29T22:53:16.933211Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['save'] = {\n",
    "    'cv_data': True,\n",
    "    'serialized_models': False,\n",
    "    'cv_scores': True,\n",
    "    'holdout_scores': False\n",
    "}\n",
    "model_dict['actions'] = {\n",
    "    'do_train_and_score_cv': True,\n",
    "    'do_score_holdout': False,\n",
    "    'do_evaluate': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store ensemble_submodel_regression__{MODEL_ID}.json for use in the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:18.264187Z",
     "start_time": "2019-08-29T22:53:18.201708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/ensemble_submodel_model__regression_example.json'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_submodel_path = 'model_configs/ensemble_submodel_model__regression_example.json'\n",
    "ensemble_submodel_path\n",
    "json.dump(model_dict, open(ensemble_submodel_path,'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify evaluate.json (evaluate_dict) if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:27.555648Z",
     "start_time": "2019-08-28T00:23:27.486885Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate_dict['to_plot'] = {\n",
    "#     'ridge': True,\n",
    "#     'thresholds': True,\n",
    "#     'bins': True,\n",
    "#     'roc': True,\n",
    "#     'accuracy_by_top_n': True,\n",
    "#     'regression__distributions': True,\n",
    "#     'regression__scatter': True,\n",
    "#     'regression__residuals_by_season_week': True,\n",
    "#     'regression__confusion_matrix': True,\n",
    "#     'shap__feature_importance': True,\n",
    "#     'shap__dependence_plots': False,\n",
    "#     'feature_importance': True\n",
    "# }\n",
    "\n",
    "# evaluate_dict['save'] = {\n",
    "#     'plots': False,\n",
    "#     'data': False\n",
    "# }\n",
    "\n",
    "# evaluate_dict['models_dir'] = f'/Users/{user}/Dropbox/data_science/modeling-football-outcomes/models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store ensemble_submodel_eval__{MODEL_ID}.json for use in the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:23.050265Z",
     "start_time": "2019-08-29T22:53:23.002143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/ensemble_submodel_evaluate__regression_example.json'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_submodel_eval_path = 'model_configs/ensemble_submodel_evaluate__regression_example.json'\n",
    "ensemble_submodel_eval_path\n",
    "json.dump(evaluate_dict, open(ensemble_submodel_eval_path,'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ensemble_evaluate.json (ensemble_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:30.939521Z",
     "start_time": "2019-08-29T22:53:30.882197Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "ensemble_eval = deepcopy(evaluate_dict)\n",
    "\n",
    "ensemble_eval['save'] = {\n",
    "    'plots': False,\n",
    "    'data': True\n",
    "}    \n",
    "\n",
    "ensemble_eval['to_plot'] = {\n",
    "    'ridge': True,\n",
    "    'thresholds': True,\n",
    "    'bins': True,\n",
    "    'roc': True,\n",
    "    'accuracy_by_top_n': True,\n",
    "    'regression__distributions': False,\n",
    "    'regression__scatter': False,\n",
    "    'regression__residuals_by_season_week': False,\n",
    "    'regression__confusion_matrix': False,\n",
    "    'shap__feature_importance': True,\n",
    "    'shap__dependence_plots': False,\n",
    "    'feature_importance': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store ensemble_evaluate__{MODEL_ID}.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:43.156747Z",
     "start_time": "2019-08-29T22:53:43.106948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/ensemble_evaluate__regression_example.json'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_evaluate_json_path = 'model_configs/ensemble_evaluate__regression_example.json'\n",
    "ensemble_evaluate_json_path\n",
    "with open(ensemble_evaluate_json_path, 'w') as w:\n",
    "    json.dump(ensemble_eval, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ensemble by generating new CV data\n",
    "### Create ensemble.json (ensemble_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:53:58.494588Z",
     "start_time": "2019-08-29T22:53:58.437342Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_dict = {}\n",
    "ensemble_dict['models_dir'] = f'/Users/{user}/Dropbox/data_science/modeling-football-outcomes/models'\n",
    "ensemble_dict['ensemble_model_id'] = 'ensemble_with_new_cv_data'\n",
    "ensemble_dict['number_of_models'] = 5\n",
    "ensemble_dict['aggregation_method'] = ['mean', 'median'] # mean, median, max, min, mean excluding top/bottom n (robust mean?)\n",
    "ensemble_dict['source'] = ensemble_submodel_path\n",
    "ensemble_dict['save'] = {'scores': True}\n",
    "\n",
    "ensemble_dict['evaluation_config'] = ensemble_submodel_eval_path\n",
    "ensemble_dict['submodel_plots'] = True\n",
    "\n",
    "assert os.path.exists(ensemble_dict['models_dir'])\n",
    "assert not set(ensemble_dict['aggregation_method']) - set(['mean','median','min','max'])\n",
    "if 'load_cv_data' not in ensemble_dict.keys():\n",
    "    assert (type(ensemble_dict['source']) is str) | (len(ensemble_dict['source']) == ensemble_dict['number_of_models'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of modifying ensemble.json: each model in the ensemble gets a random 5 features (ensemble_dict['input_changes_by_iteration']['features_list'] contains a list of N lists of 5 random features each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:27.892305Z",
     "start_time": "2019-08-28T00:23:27.778343Z"
    }
   },
   "outputs": [],
   "source": [
    "# features_list = pd.read_csv('data/{}/{}.csv'.format(\n",
    "#     *model_dict['features_tbl'].split('.'))\n",
    "# ).columns.tolist()[3:]\n",
    "\n",
    "# features_lists = [\n",
    "#     list(set(np.random.choice(features_list, size=5).tolist()))\n",
    "#     for _ in range(ensemble_dict['number_of_models'])\n",
    "# ]\n",
    "\n",
    "# ensemble_dict['input_changes_by_iteration'] = {\n",
    "#     'features_list': features_lists\n",
    "# }\n",
    "\n",
    "# # test\n",
    "# if 'input_changes_by_iteration' in ensemble_dict:\n",
    "#     assert type(ensemble_dict['input_changes_by_iteration']) is dict\n",
    "#     for param, values in ensemble_dict['input_changes_by_iteration'].items():\n",
    "#         assert len(values) == ensemble_dict['number_of_models']\n",
    "#         for value in values:\n",
    "#             assert type(value) == type(model_dict[param])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store ensemble_new_cv__{MODEL_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:54:21.425182Z",
     "start_time": "2019-08-29T22:54:21.371686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/ensemble_model_new_cv__regression_example.json'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model_json_path = 'model_configs/ensemble_model_new_cv__regression_example.json'\n",
    "ensemble_model_json_path\n",
    "with open(ensemble_model_json_path, 'w') as w:\n",
    "    json.dump(ensemble_dict, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:33.642762Z",
     "start_time": "2019-08-28T00:23:27.941376Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed /Users/jplotkin/Dropbox/data_science/modeling-football-outcomes/models/ensemble_with_new_cv_data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/jplotkin/Dropbox/data_science/modeling-football-outcomes/models/ensemble_with_new_cv_data/00002/scores/cv_scores.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0bda531a7b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnsemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_model_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble_evaluate_json_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/Ensemble.py\u001b[0m in \u001b[0;36mexecute_ensemble\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score_ensemble_from_source_cv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_score_ensemble_from_new_cv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_json_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/Ensemble.py\u001b[0m in \u001b[0;36mtrain_score_ensemble_from_new_cv_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_score_ensemble_from_new_cv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_ensemble_dir_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_submodel_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/Ensemble.py\u001b[0m in \u001b[0;36mtrain_and_score\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_nbr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'number_of_models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_submodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_nbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_submodel_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/Ensemble.py\u001b[0m in \u001b[0;36mexecute_submodel\u001b[0;34m(self, model_nbr)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExecuteModelPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_model_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_classification_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/ExecuteModelPipeline.py\u001b[0m in \u001b[0;36mexecute_model_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'actions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'do_train_and_score_cv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_score_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trained and scored'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/ExecuteModelPipeline.py\u001b[0m in \u001b[0;36mtrain_and_score_cv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainAndScoreModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_classification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         model.cv_train_and_score(self.model_data['training'],\n\u001b[0;32m---> 71\u001b[0;31m                                  self.model_data['scoring_only'])\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/data_science/modeling-football-outcomes/model_pipeline/TrainAndScoreModel.py\u001b[0m in \u001b[0;36mcv_train_and_score\u001b[0;34m(self, training, scoring_only)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_cv_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/cv_scores.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         self.model_objects = {set_nbr : mdl['model'] for set_nbr, model\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 3020\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/jplotkin/Dropbox/data_science/modeling-football-outcomes/models/ensemble_with_new_cv_data/00002/scores/cv_scores.csv'"
     ]
    }
   ],
   "source": [
    "ensemble = Ensemble(ensemble_model_json_path, ensemble_evaluate_json_path)\n",
    "ensemble.execute_ensemble()\n",
    "ensemble.evaluate_ensemble()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy ensemble CV data for a new ensemble\n",
    "#### Use cases\n",
    "* hyperparameter optimization (change only the hyperparameters in each sub-model's model.json file)\n",
    "* __feature selection if base models (and cv_data) include all features__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ensemble.json (ensemble_dict) for a new ensemble that loads CV data from another ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:55:03.250348Z",
     "start_time": "2019-08-29T22:55:03.203074Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_dict_load_cv = {}\n",
    "ensemble_dict_load_cv['models_dir'] = f'/Users/{user}/Dropbox/data_science/modeling-football-outcomes/models'\n",
    "ensemble_dict_load_cv['ensemble_model_id'] = 'ensemble_load_cv'\n",
    "ensemble_dict_load_cv['load_cv_data_from'] = ensemble_dict['ensemble_model_id']\n",
    "ensemble_dict_load_cv['number_of_models'] = 5\n",
    "ensemble_dict_load_cv['save'] = {'scores': True}\n",
    "ensemble_dict_load_cv['evaluation_config'] = ensemble_evaluate_json_path\n",
    "ensemble_dict_load_cv['submodel_plots'] = False\n",
    "ensemble_dict_load_cv['aggregation_method'] = ['mean', 'median'] # mean, median, max, min, mean excluding top/bottom n (robust mean?)\n",
    "\n",
    "assert os.path.exists(ensemble_dict_load_cv['models_dir'])\n",
    "assert not set(ensemble_dict_load_cv['aggregation_method']) - set(['mean','median','min','max'])\n",
    "if 'load_cv_data_from' in ensemble_dict_load_cv.keys():\n",
    "    assert os.path.exists(\n",
    "        os.path.join(ensemble_dict_load_cv['models_dir'], \n",
    "                     ensemble_dict_load_cv['load_cv_data_from'])\n",
    "        )\n",
    "    \n",
    "    source_path = os.path.join(ensemble_dict_load_cv['models_dir'], \n",
    "                               ensemble_dict_load_cv['load_cv_data_from'])\n",
    "    n_models_expected = 0\n",
    "    for d in os.listdir(source_path):\n",
    "        try:\n",
    "            _ = int(d)\n",
    "            n_models_expected += 1\n",
    "        except:\n",
    "            pass\n",
    "    assert ensemble_dict_load_cv['number_of_models'] == n_models_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:59:12.740218Z",
     "start_time": "2019-08-29T22:59:12.574188Z"
    }
   },
   "outputs": [],
   "source": [
    "params_lists = []\n",
    "for n in range(ensemble_dict['number_of_models']):\n",
    "    model_dict['model_params']['max_depth'] = 12\n",
    "    params_lists.append(model_dict['model_params'])\n",
    "\n",
    "ensemble_dict_load_cv['input_changes_by_iteration'] = {\n",
    "    'model_params': params_lists\n",
    "}\n",
    "\n",
    "# # test\n",
    "if 'input_changes_by_iteration' in ensemble_dict:\n",
    "    assert type(ensemble_dict['input_changes_by_iteration']) is dict\n",
    "    for param, values in ensemble_dict['input_changes_by_iteration'].items():\n",
    "        assert len(values) == ensemble_dict['number_of_models']\n",
    "        for value in values:\n",
    "            assert type(value) == type(model_dict[param])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T02:53:31.969115Z",
     "start_time": "2019-08-05T02:52:15.758Z"
    }
   },
   "source": [
    "#### Store ensemble_load_cv__{MODEL_ID}.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-29T22:59:18.252121Z",
     "start_time": "2019-08-29T22:59:18.187098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_configs/ensemble_model_load_cv__regression_example.json'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model_json_path = 'model_configs/ensemble_model_load_cv__regression_example.json'\n",
    "ensemble_model_json_path\n",
    "with open(ensemble_model_json_path, 'w') as w:\n",
    "    json.dump(ensemble_dict_load_cv, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T00:23:33.648491Z",
     "start_time": "2019-08-28T00:23:06.712Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "ensemble = Ensemble(ensemble_model_json_path, ensemble_evaluate_json_path)\n",
    "ensemble.execute_ensemble()\n",
    "ensemble.evaluate_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
