{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.217952Z",
     "start_time": "2019-03-01T00:28:50.736625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../config/initialize.ipynb\n",
    "\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* how to generalize to regression problems?\n",
    "  * easier to create a separate process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set root dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.252148Z",
     "start_time": "2019-03-01T00:28:56.245377Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT='/Users/joshplotkin/Dropbox/data_science/'\\\n",
    "    'modeling-football-outcomes/models'\n",
    "os.chdir(ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "* set model ID\n",
    "* remove this model ID's directory if it exists\n",
    "* create directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.268242Z",
     "start_time": "2019-03-01T00:28:56.258158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory models/0228_with_rankings_winner_20feats_noml **DOES NOT EXIST**\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = '0228_with_rankings_winner_20feats_noml'\n",
    "\n",
    "if os.path.exists(MODEL_ID):\n",
    "    print 'Directory models/{} **EXISTS**'.format(MODEL_ID)    \n",
    "else:\n",
    "    print 'Directory models/{} **DOES NOT EXIST**'.format(MODEL_ID)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.281197Z",
     "start_time": "2019-03-01T00:28:56.274359Z"
    }
   },
   "outputs": [],
   "source": [
    "## wipe out existing directory\n",
    "if os.path.exists(MODEL_ID):\n",
    "    shutil.rmtree(MODEL_ID)\n",
    "os.mkdir(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dictionary version of model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.293110Z",
     "start_time": "2019-03-01T00:28:56.286848Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict = {'model_id': MODEL_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source data for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hive Tables\n",
    "* features\n",
    "* tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.305808Z",
     "start_time": "2019-03-01T00:28:56.299143Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['features_tbl'] = 'features.combined_0127'\n",
    "model_dict['labels_tbl'] = 'labels.combined_0127'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.317422Z",
     "start_time": "2019-03-01T00:28:56.310913Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels = spark.table('labels.combined_0128').select(\n",
    "#         ## index\n",
    "#         'game_id',\n",
    "#         ## strata\n",
    "#         ## labels\n",
    "#         'did_cover_sbr',\n",
    "#         'did_win'\n",
    "#     )\n",
    "\n",
    "# labels.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.327498Z",
     "start_time": "2019-03-01T00:28:56.322340Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels_tbl = 'labels.0127_home_team'\n",
    "# labels.write.mode('overwrite').saveAsTable(labels_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.337561Z",
     "start_time": "2019-03-01T00:28:56.332491Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_dict['labels_tbl'] = labels_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns from Hive tables\n",
    "* index: unique identifier in features/labels table (must be in both)\n",
    "* label column, and indicator of what is a positive label\n",
    "  * currently not supported: multi-class\n",
    "  * code will binarize\n",
    "* list of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.356858Z",
     "start_time": "2019-03-01T00:28:56.342934Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['index'] = ['game_id']\n",
    "model_dict['label_col'] = 'did_win'\n",
    "model_dict['pos_labels'] = [1]\n",
    "model_dict['neg_labels'] = [-1]\n",
    "model_dict['features_list'] = ['rankings___h__estim_winrate',\n",
    " 'rankings___v__offensedvoa',\n",
    " 'rankings___h__dave_or_wtddvoa',\n",
    " 'travel___v_travel_from_last_game_decay',\n",
    " 'rankings___h__offensedvoa',\n",
    " 'rankings___v__dave_or_wtddvoa',\n",
    " 'rankings___h__s_t_dvoa',\n",
    " 'rankings___v__s_t_dvoa',\n",
    " 'travel___h_travel_from_last_game_decay',\n",
    " 'rankings___v__defensedvoa',\n",
    " 'rankings___v__estim_winrate',\n",
    " 'team_history___v_ovr_wr_past_3_seasons',\n",
    " 'rankings___h__defensedvoa',\n",
    " 'team_history___h_ovr_wr_past_3_seasons',\n",
    " 'weather___wind_chill',\n",
    " 'home_field___v_visitor__ovr_wr_ytd',\n",
    " 'home_field___v_visitor__ovr_wr_last_8_games',\n",
    " 'weather___wind_mph',\n",
    " 'weather___humidity_pct',\n",
    " 'team_history___h_ovr_wr_ytd']\n",
    "\n",
    "model_dict['features_list'].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:28:56.375595Z",
     "start_time": "2019-03-01T00:28:56.362249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home_field___v_visitor__ovr_wr_last_8_games',\n",
       " 'home_field___v_visitor__ovr_wr_ytd',\n",
       " 'rankings___h__dave_or_wtddvoa',\n",
       " 'rankings___h__defensedvoa',\n",
       " 'rankings___h__estim_winrate',\n",
       " 'rankings___h__offensedvoa',\n",
       " 'rankings___h__s_t_dvoa',\n",
       " 'rankings___v__dave_or_wtddvoa',\n",
       " 'rankings___v__defensedvoa',\n",
       " 'rankings___v__estim_winrate',\n",
       " 'rankings___v__offensedvoa',\n",
       " 'rankings___v__s_t_dvoa',\n",
       " 'team_history___h_ovr_wr_past_3_seasons',\n",
       " 'team_history___h_ovr_wr_ytd',\n",
       " 'team_history___v_ovr_wr_past_3_seasons',\n",
       " 'travel___h_travel_from_last_game_decay',\n",
       " 'travel___v_travel_from_last_game_decay',\n",
       " 'weather___humidity_pct',\n",
       " 'weather___wind_chill',\n",
       " 'weather___wind_mph']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict['features_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:01.136167Z",
     "start_time": "2019-03-01T00:28:56.381752Z"
    }
   },
   "outputs": [],
   "source": [
    "## assert these fields are of the correct type\n",
    "assert type(model_dict['index']) is list\n",
    "assert type(model_dict['label_col']) is str\n",
    "assert type(model_dict['features_tbl']) is str\n",
    "assert type(model_dict['features_tbl']) is str\n",
    "assert type(model_dict['features_list']) is list\n",
    "assert type(model_dict['pos_labels']) is list\n",
    "\n",
    "## assert format is schema.table and that\n",
    "## table exists in hive\n",
    "for tbl_str in ['features_tbl','features_tbl']:\n",
    "    schema_and_tbl = model_dict[tbl_str].split('.')\n",
    "    assert len(schema_and_tbl) == 2\n",
    "    schema, tbl = schema_and_tbl\n",
    "    assert spark.sql(\n",
    "            'show tables in {}'.format(schema)\n",
    "        ).filter(\n",
    "            col('tableName') == tbl\n",
    "        ).count() == 1\n",
    "\n",
    "feat_cols_set = set(spark.table(model_dict['features_tbl']).columns)\n",
    "label_cols_set = set(spark.table(model_dict['labels_tbl']).columns)\n",
    "idx_set = set(model_dict['index'])\n",
    "feat_set = set(model_dict['features_list'])\n",
    "label_set = set([model_dict['label_col']])\n",
    "\n",
    "## assert the chosen columns exist in the\n",
    "## chosen tables\n",
    "assert not idx_set - feat_cols_set\n",
    "assert not idx_set - label_cols_set\n",
    "assert not feat_set - feat_cols_set\n",
    "assert not label_set - label_cols_set\n",
    "\n",
    "## check that positive and negative label values \n",
    "## are valid\n",
    "for label_val in ['pos_labels','neg_labels']:\n",
    "    assert spark.table(\n",
    "            model_dict['labels_tbl']\n",
    "        ).filter(\n",
    "            col(model_dict['label_col']).isin(model_dict[label_val])\n",
    "        ).count() > 0\n",
    "    \n",
    "## assert that labels and features share identical index\n",
    "a = spark.table(model_dict['features_tbl']).count()\n",
    "b = spark.table(model_dict['labels_tbl']).count()\n",
    "c = spark.table(model_dict['features_tbl']).join(\n",
    "    spark.table(model_dict['labels_tbl']),\n",
    "    on=model_dict['index']\n",
    ").count()\n",
    "assert a == b\n",
    "assert a == c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation Sets\n",
    "* random seeds for reproducibility\n",
    "* number of folds for cross-validation (value of <= 1 doesn't do k-fold\n",
    "* global_dataset_proportions\n",
    " * proportion of the data for each of training, scoring only, holdout, and throwaway\n",
    " * generated using stratified sampling\n",
    "* dimensional_dataset_proportions\n",
    " * post-processing after global_dataset_proportions\n",
    " * idea is to move specific field values, e.g. move certain seasons to the holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: use cross-validation data from another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:01.147520Z",
     "start_time": "2019-03-01T00:29:01.141915Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['model_cv_to_use'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV parameters, when not using another model CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample usage for Dimensional Dataset Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T23:45:00.946875Z",
     "start_time": "2019-02-28T23:45:00.932060Z"
    }
   },
   "source": [
    "```python\n",
    "model_dict['dimensional_dataset_proportions'] = {\n",
    "        'throw_away': [\n",
    "            {\n",
    "                'vals': [\n",
    "                    0\n",
    "                ], \n",
    "                'dim': 'is_home',\n",
    "                'prop_to_move': 1.0, \n",
    "                'from_groups': [\n",
    "                    'in_training',\n",
    "                    'holdout',\n",
    "                    'scoring_only'\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:01.174357Z",
     "start_time": "2019-03-01T00:29:01.152943Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['kfold_seed'] = 99\n",
    "model_dict['dataset_seed'] = 9\n",
    "model_dict['kfolds'] = 5\n",
    "model_dict['strata_cols'] = ['did_cover_sbr','week_id']\n",
    "model_dict['holdout_set'] = {\n",
    "    'store_to_disk': False,\n",
    "    'score_using_full_model': False \n",
    "}\n",
    "\n",
    "model_dict['global_dataset_proportions'] = {\n",
    "        'in_training': 1.,\n",
    "        'holdout': 0,\n",
    "        'throw_away': 0,\n",
    "        'scoring_only': 0\n",
    "    }\n",
    "\n",
    "# DEFAULT: model_dict['dimensional_dataset_proportions'] = {}\n",
    "model_dict['dimensional_dataset_proportions'] = {\n",
    "        'throw_away': [\n",
    "            {\n",
    "                'vals': [\n",
    "                    1, 2, 3, 4, 17, 18, 19, 20, 21, 22\n",
    "                ], \n",
    "                'dim': 'week_id',\n",
    "                'prop_to_move': 1.0, \n",
    "                'from_groups': [\n",
    "                    'in_training',\n",
    "                    'holdout',\n",
    "                    'scoring_only'\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:01.248998Z",
     "start_time": "2019-03-01T00:29:01.180812Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_dict['model_cv_to_use']:\n",
    "    assert type(model_dict['model_cv_to_use']) in [str, unicode]\n",
    "    assert os.path.exists(model_dict['model_cv_to_use'])\n",
    "else:\n",
    "    ## assert the data structures/types are correct\n",
    "    assert type(model_dict['kfold_seed']) is int\n",
    "    assert type(model_dict['dataset_seed']) is int\n",
    "    assert type(model_dict['kfolds']) is int\n",
    "    assert type(model_dict['strata_cols']) is list\n",
    "    assert type(model_dict['global_dataset_proportions']) is dict\n",
    "    assert type(model_dict['dimensional_dataset_proportions']) is dict\n",
    "    assert type(model_dict['holdout_set']) is dict\n",
    "\n",
    "    ## assert strata cols are present in the labels table\n",
    "    assert not set(model_dict['strata_cols']) - label_cols_set\n",
    "\n",
    "    dataset_types = set(['in_training','holdout','throw_away','scoring_only'])\n",
    "    global_datasets = model_dict['global_dataset_proportions']\n",
    "    dim_datasets = model_dict['dimensional_dataset_proportions']\n",
    "\n",
    "    ## assert global_dataset_proportions has all possible dataset types\n",
    "    assert set(global_datasets.keys()) == dataset_types\n",
    "    ## values are proportions that must sum to 1\n",
    "    assert sum(global_datasets.values()) == 1\n",
    "    ## assert that the keys are valid dataset types\n",
    "    assert not set(dim_datasets.keys()) - dataset_types\n",
    "    ## assert the following (in order of assertion block):\n",
    "    ## (1) each value is a list\n",
    "    ## (2) each element of the list is a dict\n",
    "    ## (3) each dict has the 5 required keys\n",
    "    ## (4) the \"dim\" field is in the strata columns \n",
    "    ## (5) \"prop_to_move\" field is [0, 1]\n",
    "    ## (6) \"from_groups\" are in the possible dataset types\n",
    "    for k, dim_list in dim_datasets.iteritems():\n",
    "        assert (type(dim_list)) is list\n",
    "        for entry in dim_list:\n",
    "            assert type(entry) is dict\n",
    "            assert set(entry.keys()) \\\n",
    "                    == set(['vals','dim','prop_to_move','from_groups'])\n",
    "            assert entry['dim'] in model_dict['strata_cols']\n",
    "            assert 0 <= entry['prop_to_move'] <= 1\n",
    "            assert not set(entry['from_groups']) - dataset_types\n",
    "\n",
    "    ## assert holdout set has 2 keys (store_to_disk, score_using_full_model)\n",
    "    ## and the corresponding values are boolean\n",
    "    assert set(model_dict['holdout_set'].keys()) \\\n",
    "            == set(['store_to_disk','score_using_full_model'])\n",
    "    assert len(filter(\n",
    "        lambda x: type(x) is not bool, \n",
    "        model_dict['holdout_set'].values()\n",
    "    )) == 0\n",
    "    ## if holdout data isn't stored, it can't be scored\n",
    "    assert not (model_dict['holdout_set']['store_to_disk'] is False) \\\n",
    "                & (model_dict['holdout_set']['score_using_full_model'] is True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Choice\n",
    "* package/class name as a string\n",
    "* parameters as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:01.264077Z",
     "start_time": "2019-03-01T00:29:01.254902Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict['model'] = 'sklearn.ensemble.GradientBoostingClassifier'\n",
    "model_dict['model_params'] = {\n",
    "    'learning_rate': 0.1, \n",
    "    'n_estimators': 200, \n",
    "    'max_features': 'auto', \n",
    "    'subsample': 0.9, \n",
    "    'random_state': 9, \n",
    "    'max_depth': 12, \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:01.279339Z",
     "start_time": "2019-03-01T00:29:01.270283Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_dict['model'] = 'xgboost.XGBClassifier'\n",
    "# model_dict['model_params'] = {\n",
    "#         'n_jobs': 1, \n",
    "#         'learning_rate': 0.1, \n",
    "#         'n_estimators': 200, \n",
    "#         'max_features': 'auto', \n",
    "#         'booster': 'gbtree', \n",
    "#         'silent': True, \n",
    "#         'nthread': None, \n",
    "#         'subsample': 0.9, \n",
    "#         'random_state': 9, \n",
    "#         'objective': 'binary:logistic', \n",
    "#         'max_depth': 12, \n",
    "#         'gamma': 0\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.552034Z",
     "start_time": "2019-03-01T00:29:01.284663Z"
    }
   },
   "outputs": [],
   "source": [
    "## test that model object can be created\n",
    "## from model inputs\n",
    "try:\n",
    "    import importlib\n",
    "\n",
    "    model_class_str = model_dict['model']\n",
    "    model_obj_path = '.'.join(model_class_str.split('.')[:-1])\n",
    "    model_name = model_class_str.split('.')[-1]\n",
    "    model_package = importlib.import_module(model_obj_path)\n",
    "    model_class = getattr(model_package, model_name)\n",
    "    _ = model_class(**model_dict['model_params'])\n",
    "except Exception as e:\n",
    "    e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out model.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.566677Z",
     "start_time": "2019-03-01T00:29:02.557266Z"
    }
   },
   "outputs": [],
   "source": [
    "model_json_path = '{}/model.json'.format(model_dict['model_id'])\n",
    "assert os.path.exists(model_dict['model_id'])\n",
    "assert not os.path.exists(model_json_path)\n",
    "\n",
    "with open(model_json_path,'w') as w:\n",
    "    json.dump(model_dict, w, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dictionary version of plots.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.580459Z",
     "start_time": "2019-03-01T00:29:02.571959Z"
    }
   },
   "outputs": [],
   "source": [
    "plots_dict = {'model_id': MODEL_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Labels\n",
    "* labels --> names (note: keys should be strings)\n",
    "* name for success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.595944Z",
     "start_time": "2019-03-01T00:29:02.587142Z"
    }
   },
   "outputs": [],
   "source": [
    "plots_dict['label_map'] = {\n",
    "    '1': 'Won',\n",
    "    '0': 'Lost'\n",
    "}\n",
    "plots_dict['success_name'] = 'Win Rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.612314Z",
     "start_time": "2019-03-01T00:29:02.602405Z"
    }
   },
   "outputs": [],
   "source": [
    "assert type(plots_dict['label_map']) is dict\n",
    "assert type(plots_dict['success_name']) is str\n",
    "assert set(plots_dict['label_map'].keys()) == set(['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bins to plot\n",
    "* plot_bins: \n",
    "   * Number of bins to plot (i.e. number of bars on the bar chart)\n",
    "* bin_types:\n",
    "   * \"Bin\" puts scores into uniform bins, e.g. [0, 0.10], (0.10, 0.20], ..., (0.9, 1.0]\n",
    "   * \"Percentile\" bins scores into ntiles determined by plot_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.624931Z",
     "start_time": "2019-03-01T00:29:02.618124Z"
    }
   },
   "outputs": [],
   "source": [
    "plots_dict['bin_types'] = ['Bin', 'Percentile']\n",
    "plots_dict['plot_bins'] = [10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.639102Z",
     "start_time": "2019-03-01T00:29:02.630899Z"
    }
   },
   "outputs": [],
   "source": [
    "## currently only supports \"Bin\" and \"Percentile\"\n",
    "assert not set(plots_dict['bin_types']) - set(['Bin','Percentile'])\n",
    "## all plot bins values should be ints\n",
    "assert plots_dict['plot_bins'] == map(int, plots_dict['plot_bins'])\n",
    "## ensure all bins values are in [2, 1000]\n",
    "assert filter(\n",
    "        lambda x: 2 <= x <= 1000, plots_dict['plot_bins']\n",
    "    )   == plots_dict['plot_bins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T05:11:29.935287Z",
     "start_time": "2019-01-14T05:11:29.928839Z"
    }
   },
   "source": [
    "### Threshold Metrics to Plot\n",
    "* metrics evaluated at each of 100 score threshold points\n",
    "* currently only supports Accuracy and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.649778Z",
     "start_time": "2019-03-01T00:29:02.644352Z"
    }
   },
   "outputs": [],
   "source": [
    "plots_dict['threshold_metrics'] = ['Accuracy','F1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.660836Z",
     "start_time": "2019-03-01T00:29:02.654781Z"
    }
   },
   "outputs": [],
   "source": [
    "assert type(plots_dict['threshold_metrics']) is list\n",
    "## currently only supports Accuracy and F1\n",
    "assert not set(plots_dict['threshold_metrics']) - set(['Accuracy','F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:15:57.428617Z",
     "start_time": "2019-01-14T17:15:57.423675Z"
    }
   },
   "source": [
    "### Write out plots.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:29:02.673813Z",
     "start_time": "2019-03-01T00:29:02.666302Z"
    }
   },
   "outputs": [],
   "source": [
    "plots_json_path = '{}/plots.json'.format(model_dict['model_id'])\n",
    "assert not os.path.exists(plots_json_path)\n",
    "\n",
    "with open(plots_json_path,'w') as w:\n",
    "    json.dump(plots_dict, w, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:30:13.768753Z",
     "start_time": "2019-03-01T00:29:02.679509Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0228_with_rankings_winner_20feats_noml'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check JSON files\n",
      "\n",
      "real\t0m13.965s\n",
      "user\t0m35.050s\n",
      "sys\t0m2.478s\n",
      "\n",
      "Cross-validation data\n",
      "\n",
      "real\t0m24.649s\n",
      "user\t1m29.561s\n",
      "sys\t0m8.526s\n",
      "\n",
      "Train and score\n",
      "\n",
      "real\t0m22.073s\n",
      "user\t0m20.892s\n",
      "sys\t0m1.121s\n",
      "\n",
      "Evaluate and plot\n",
      "\n",
      "real\t0m7.581s\n",
      "user\t0m6.864s\n",
      "sys\t0m1.107s\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID\n",
    "!source ~/.bashrc && \\\n",
    "    unset PYSPARK_PYTHON && \\\n",
    "    unset PYSPARK_DRIVER_PYTHON && \\\n",
    "    unset PYSPARK_DRIVER_PYTHON_OPTS && \\\n",
    "    cd /Users/joshplotkin/Dropbox/data_science/modeling-football-outcomes/ && \\\n",
    "    model_pipeline/model_pipeline.sh {MODEL_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:30:13.921108Z",
     "start_time": "2019-03-01T00:30:13.774925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON configuration files passed checks.\r\n",
      "cv sets wrote successfully.\r\n",
      "successfully completed evaluation and plotting.\r\n"
     ]
    }
   ],
   "source": [
    "!cat /Users/joshplotkin/Dropbox/data_science/modeling-football-outcomes/models/{MODEL_ID}/logs/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T00:30:14.310783Z",
     "start_time": "2019-03-01T00:30:13.929543Z"
    }
   },
   "outputs": [],
   "source": [
    "!open {MODEL_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
