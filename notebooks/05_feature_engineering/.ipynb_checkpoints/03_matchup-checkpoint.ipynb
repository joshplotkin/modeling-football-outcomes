{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:48.547647Z",
     "start_time": "2019-01-27T06:32:42.177891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../config/initialize.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:48.572550Z",
     "start_time": "2019-01-27T06:32:48.553074Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_window(window_type, n, partition_cols, date_orderby_col):\n",
    "    '''accepts window type (days, games, seasons),\n",
    "     size of window n,\n",
    "     and window fields (partition and sort), \n",
    "     and returns a spark Window'''\n",
    "    assert type(partition_cols) is list\n",
    "    assert type(date_orderby_col) is str\n",
    "    assert type(n) is int\n",
    "    assert window_type in ['games','days','seasons']\n",
    "    \n",
    "    from pyspark.sql.window import Window\n",
    "    if window_type == 'games':\n",
    "        ## fixed number of games\n",
    "        return Window.partitionBy(*partition_cols)\\\n",
    "                  .orderBy(col(date_orderby_col).desc())\\\n",
    "                  .rowsBetween(1, n)\n",
    "\n",
    "    elif window_type == 'days':\n",
    "        ## fixed number of days\n",
    "        seconds = 24*60*60*n\n",
    "        return Window.partitionBy(*partition_cols)\\\n",
    "                  .orderBy(col(date_orderby_col).cast('timestamp').cast('long'))\\\n",
    "                  .rangeBetween(-seconds, -1)\n",
    "\n",
    "    elif window_type == 'seasons':\n",
    "        ## fixed number of seasons, including current\n",
    "        ## n = 1 is YTD\n",
    "        seconds = 24*60*60*(180 + 365*(n-1))\n",
    "        return Window.partitionBy(*partition_cols)\\\n",
    "                  .orderBy(col(date_orderby_col).cast('timestamp').cast('long'))\\\n",
    "                  .rangeBetween(-seconds, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matchup Features\n",
    "* key: (game_id)\n",
    "* table name: features.matchup\n",
    "* __is_same_division__\n",
    "* __is_same_conf__\n",
    "* __h_wr_past_5_games__\n",
    "* __h_wr_ytd__\n",
    "* __h_wr_past_2_seasons__\n",
    "* __h_wr_past_3_seasons__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:48.588928Z",
     "start_time": "2019-01-27T06:32:48.578466Z"
    }
   },
   "outputs": [],
   "source": [
    "key = 'game_id'\n",
    "out_tbl = 'features.matchup'\n",
    "features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:52.152932Z",
     "start_time": "2019-01-27T06:32:48.596920Z"
    }
   },
   "outputs": [],
   "source": [
    "games = spark.table('game').select('game_id','h_team_id','date',\n",
    "                                   'v_team_id','season','matchup_id')\n",
    "\n",
    "h_team = spark.table('team_season')\\\n",
    "     .select('team_id','season','division','name')\\\n",
    "     .withColumnRenamed('team_id','h_team_id')\\\n",
    "     .withColumnRenamed('division','h_division')\\\n",
    "     .withColumnRenamed('name','h_name')\n",
    "\n",
    "v_team = spark.table('team_season')\\\n",
    "     .select('team_id','season','division','name')\\\n",
    "     .withColumnRenamed('team_id','v_team_id')\\\n",
    "     .withColumnRenamed('division','v_division')\\\n",
    "     .withColumnRenamed('name','v_name')\n",
    "\n",
    "teams = games.join(h_team, on=['h_team_id','season'])\\\n",
    "             .join(v_team, on=['v_team_id','season'])\n",
    "\n",
    "assert teams.count() == games.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T03:39:33.402788Z",
     "start_time": "2019-01-21T03:39:31.249712Z"
    }
   },
   "source": [
    "* ### is intra-division\n",
    "* ### is intra-conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:55.728524Z",
     "start_time": "2019-01-27T06:32:52.158801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_same_division</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_same_division    0.0   1.0\n",
       "0               0.0  715.0  1153\n",
       "1               1.0    0.0  1069"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = teams.withColumn(\n",
    "        'is_same_division', \n",
    "        F.when(\n",
    "            col('h_division') == col('v_division'),\n",
    "            1.\n",
    "        ).otherwise(0.)\n",
    "    ).withColumn(\n",
    "        'is_same_conf', \n",
    "        F.when(\n",
    "            F.split('h_division', ' ')[0] == F.split('v_division', ' ')[0],\n",
    "            1.\n",
    "        ).otherwise(0.)\n",
    "    )\n",
    "\n",
    "teams.groupby('is_same_division').pivot('is_same_conf').count()\\\n",
    "    .toPandas().fillna(0)\n",
    "\n",
    "features_list += ['is_same_division','is_same_conf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head-to-head record recent history\n",
    "\n",
    "* last 5 games, 5 years, etc.\n",
    "* requires window\n",
    "* __h_wr_last_5_games__\n",
    "* __h_wr_last_365_days__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:55.750870Z",
     "start_time": "2019-01-27T06:32:55.734297Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wr_over_window(df, w, feat_name):\n",
    "    '''Takes Spark DF, Spark Window obj,\n",
    "    and new column name,\n",
    "    and computes the home team winrate\n",
    "    over the window'''\n",
    "    first_team = F.substring('matchup_id', 0, 3)\n",
    "    \n",
    "    return df.withColumn(\n",
    "        feat_name, \n",
    "        ## sum of home team wins\n",
    "        ## tie is 0.5\n",
    "        F.sum(\n",
    "            F.when(col('winner') == first_team, 1.)\n",
    "             .when(col('winner') == '', 0.5)\n",
    "             .otherwise(0.)\n",
    "        ).over(w) \n",
    "        ## divided by count for winrate\n",
    "        / F.count(F.lit(1)).over(w)\n",
    "    ).withColumn(\n",
    "        feat_name,\n",
    "        F.when(first_team == col('h_team_id'), \n",
    "               col(feat_name))\n",
    "         .otherwise(1 - col(feat_name))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:55.889673Z",
     "start_time": "2019-01-27T06:32:55.756360Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = spark.table('game_outcome').select('game_id','h_final','v_final')\n",
    "\n",
    "teams_score = teams.join(\n",
    "        scores, on='game_id'\n",
    "    ).withColumn(\n",
    "        'winner', \n",
    "        F.when(col('h_final') > col('v_final'), col('h_team_id'))\n",
    "         .when(col('h_final') < col('v_final'), col('v_team_id'))\n",
    "         .otherwise('')\n",
    "    ).drop(\n",
    "        'h_final','v_final'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:56.338847Z",
     "start_time": "2019-01-27T06:32:55.895718Z"
    }
   },
   "outputs": [],
   "source": [
    "for n, window_type in [(5, 'games'), \n",
    "                       (1, 'seasons'), \n",
    "                       (2, 'seasons'),\n",
    "                       (3, 'seasons')]:\n",
    "    feat_name = 'h_wr_past_{}_{}'.format(n, window_type)\n",
    "    feat_name = feat_name.replace('past_1_seasons','ytd')\n",
    "    w = get_window(window_type, n, ['matchup_id'], 'date')\n",
    "    teams_score = get_wr_over_window(teams_score, w, feat_name)\\\n",
    "                      .fillna(0.5, feat_name)\n",
    "\n",
    "    features_list.append(feat_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test some matchups in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:32:56.353895Z",
     "start_time": "2019-01-27T06:32:56.343892Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_test_cases(df, test_cases, feat_name):\n",
    "    '''takes a Spark DF and filter conditions and\n",
    "    asserts that they hold.'''\n",
    "    for g, v in test_cases.iteritems():\n",
    "        if not v:\n",
    "            assert v == df.filter(col('game_id') == g)\\\n",
    "                    .select(feat_name)\\\n",
    "                    .toPandas().iloc[0, 0]\n",
    "        else:\n",
    "            assert np.isclose(\n",
    "                df.filter(col('game_id') == g)\\\n",
    "                    .select(feat_name)\\\n",
    "                    .toPandas().iloc[0, 0],\n",
    "                v)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:33:17.694143Z",
     "start_time": "2019-01-27T06:32:56.358412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking games...\n",
      "checking days...\n"
     ]
    }
   ],
   "source": [
    "test_cases = {}\n",
    "\n",
    "test_cases[(5, 'games')] = {\n",
    "    '200710140jax': None,\n",
    "    '200712300htx': 0.,\n",
    "    '200809280jax': 1./2,\n",
    "    '201709100htx': 1.,\n",
    "    '201712170jax': 1./5,\n",
    "    '201802040nwe': 2./3,\n",
    "    '201410020gnb': 3.5/5\n",
    "}\n",
    "test_cases[(365, 'days')] = {\n",
    "    '200710140jax': None,\n",
    "    '200712300htx': 0.,\n",
    "    '200809280jax': 1./2,\n",
    "    '201709100htx': 1.,\n",
    "    '201712170jax': 1./2,\n",
    "    '201802040nwe': None,\n",
    "    '201410020gnb': 3./4\n",
    "}\n",
    "\n",
    "test_sdf = teams_score\n",
    "for (n, window_type), v in test_cases.iteritems():\n",
    "    print 'checking {}...'.format(window_type)\n",
    "    w = get_window(window_type, n, ['matchup_id'], 'date')\n",
    "    test_sdf = get_wr_over_window(test_sdf, w, 'val')\n",
    "    check_test_cases(test_sdf, v, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-21T06:49:48.073461Z",
     "start_time": "2019-01-21T06:49:48.065429Z"
    }
   },
   "source": [
    "## Write Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:33:17.711989Z",
     "start_time": "2019-01-27T06:33:17.703885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* __is_same_division__\n",
      "* __is_same_conf__\n",
      "* __h_wr_past_5_games__\n",
      "* __h_wr_ytd__\n",
      "* __h_wr_past_2_seasons__\n",
      "* __h_wr_past_3_seasons__\n"
     ]
    }
   ],
   "source": [
    "print '* __' + '__\\n* __'.join(features_list) + '__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:33:25.802803Z",
     "start_time": "2019-01-27T06:33:17.717858Z"
    }
   },
   "outputs": [],
   "source": [
    "teams_score.select(*([key] + features_list))\\\n",
    "        .write.mode('overwrite').saveAsTable(out_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-27T06:33:26.189772Z",
     "start_time": "2019-01-27T06:33:25.810173Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>is_same_division</th>\n",
       "      <th>is_same_conf</th>\n",
       "      <th>h_wr_past_5_games</th>\n",
       "      <th>h_wr_ytd</th>\n",
       "      <th>h_wr_past_2_seasons</th>\n",
       "      <th>h_wr_past_3_seasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200709160oti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200712300clt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200810270oti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200812280clt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200910110oti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        game_id  is_same_division  is_same_conf  h_wr_past_5_games  h_wr_ytd  \\\n",
       "0  200709160oti               1.0           1.0           0.500000       0.5   \n",
       "1  200712300clt               1.0           1.0           1.000000       1.0   \n",
       "2  200810270oti               1.0           1.0           0.500000       0.5   \n",
       "3  200812280clt               1.0           1.0           0.333333       0.0   \n",
       "4  200910110oti               1.0           1.0           0.500000       0.5   \n",
       "\n",
       "   h_wr_past_2_seasons  h_wr_past_3_seasons  \n",
       "0             0.500000             0.500000  \n",
       "1             1.000000             1.000000  \n",
       "2             0.500000             0.500000  \n",
       "3             0.333333             0.333333  \n",
       "4             0.500000             0.500000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(out_tbl).limit(5).toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
